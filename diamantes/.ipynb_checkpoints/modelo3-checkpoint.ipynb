{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ce1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c13683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "      <th>cut_encoded</th>\n",
       "      <th>color_encoded</th>\n",
       "      <th>clarity_encoded</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.68</td>\n",
       "      <td>6.353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.01</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6.46</td>\n",
       "      <td>4.04</td>\n",
       "      <td>9.183</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cut color clarity  depth  table     x     y     z  price  \\\n",
       "carat                                                                 \n",
       "0.30   Premium     D     SI2   62.4   58.0  4.31  4.28  2.68  6.353   \n",
       "1.01     Ideal     E    VVS2   62.7   56.0  6.42  6.46  4.04  9.183   \n",
       "\n",
       "       cut_encoded  color_encoded  clarity_encoded  \n",
       "carat                                               \n",
       "0.30           1.0            5.0              0.0  \n",
       "1.01           4.0            6.0              5.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"TRAIN3.csv\", index_col = 0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae45048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparto de datos en train y test\n",
    "# ==============================================================================\n",
    "# Lo primero que hacemos es definir cuál es nuestra variable Y y nuestras variables X\n",
    "X = df.drop(['price', 'cut', 'color', 'clarity'], axis=1)\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3b5f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento\n",
      "-----------------------\n",
      "count    29568.000000\n",
      "mean         7.702887\n",
      "std          0.976932\n",
      "min          5.787000\n",
      "25%          6.809000\n",
      "50%          7.694000\n",
      "75%          8.505000\n",
      "max          9.842000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos de entrenamiento\")\n",
    "print(\"-----------------------\")\n",
    "print(y_train.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0bfe4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de testeo\n",
      "-----------------------\n",
      "count    7392.000000\n",
      "mean        7.702766\n",
      "std         0.985273\n",
      "min         5.817000\n",
      "25%         6.801000\n",
      "50%         7.689000\n",
      "75%         8.513250\n",
      "max         9.842000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos de testeo\")\n",
    "print(\"-----------------------\")\n",
    "print(y_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c48abb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m regressor \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# fit the regressor with X and Y data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:186\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    185\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 186\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    190\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:560\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[1;32m    559\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[0;32m--> 560\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[1;32m    562\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# create a regressor object\n",
    "regressor = DecisionTreeRegressor(random_state = 0) \n",
    "  \n",
    "# fit the regressor with X and Y data\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ec710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "tree.plot_tree(regressor, feature_names=X_train.columns, filled=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2560e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max features\n",
    "\n",
    "max_features = np.sqrt(len(X_train.columns))\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a679b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth\n",
    "\n",
    "print(regressor.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb29522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos las predicciones sobre los dos set de datos el X_test y el X_train\n",
    "y_pred_test_dt = regressor.predict(X_test)\n",
    "y_pred_train_dt = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(y_test, y_train, y_test_pred, y_train_pred, tipo_modelo):\n",
    "    \n",
    "    \n",
    "    resultados = {'MAE': [metrics.mean_absolute_error(y_test, y_test_pred), metrics.mean_absolute_error(y_train, y_train_pred)],\n",
    "                'MSE': [metrics.mean_squared_error(y_test, y_test_pred), metrics.mean_squared_error(y_train, y_train_pred)],\n",
    "                'RMSE': [np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)), np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))],\n",
    "                'R2':  [metrics.r2_score(y_test, y_test_pred), metrics.r2_score(y_train, y_train_pred)],\n",
    "                 \"set\": [\"test\", \"train\"]}\n",
    "    df = pd.DataFrame(resultados)\n",
    "    df[\"modelo\"] = tipo_modelo\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345912ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las métricas para ver si hay overfitting\n",
    "\n",
    "dt_results1 = metricas(y_test, y_train, y_pred_test_dt, y_pred_train_dt, \"Decission Tree I\")\n",
    "dt_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843789be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación del GridSearch\n",
    "# ==============================================================================\n",
    "\n",
    "# definimos un diccionario con los hiperparámetros que queremos testear. \n",
    "param = {\"max_depth\": [4, 5, 6, 7],\n",
    "        \"min_samples_split\": [10, 50, 100],\n",
    "        \"max_features\": [1,2,3,4,5,6]}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "            estimator=DecisionTreeRegressor(),\n",
    "            param_grid= param,\n",
    "            cv=10,\n",
    "            verbose=3,\n",
    "            return_train_score = True,\n",
    "            scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el modelo de nuevo\n",
    "\n",
    "%time\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97209ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos cual es el mejor de todos los que hemos testeado usando el método best_estimator_\n",
    "\n",
    "best_tree = gs.best_estimator_\n",
    "best_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volvamos a intentar visualizar el árbol a ver como se ve: \n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "tree.plot_tree(best_tree, feature_names=X_train.columns, filled=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46959364",
   "metadata": {},
   "outputs": [],
   "source": [
    " #guardamos la imagen \n",
    "\n",
    "fig.savefig(\"decision_tree.png\", facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe132e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.export_text(best_tree, feature_names= list(X_train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_dt2 = best_tree.predict(X_test)\n",
    "y_pred_train_dt2 = best_tree.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results2 = metricas(y_test, y_train, y_pred_test_dt2, y_pred_train_dt2, \"Decision tree II\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d142aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c8e5d",
   "metadata": {},
   "source": [
    "# prueba predicciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f57504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"realidad3.csv\", index_col = 0)\n",
    "X_realida = df.drop(['cut', 'color', 'clarity'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db135f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_realida_submision = best_tree.predict(X_realida)\n",
    "X_realida_submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5055bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submision1 = pd.DataFrame(X_realida_submision)\n",
    "submision1.reset_index(inplace=True)\n",
    "submision1.rename(columns={\"index\":\"id\",0:\"price\"}, inplace =True)\n",
    "submision1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submision1.to_csv(\"valen3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b50acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
